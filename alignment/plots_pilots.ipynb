{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8766022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/repos/Deep-JSCC-PyTorch\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import copy\n",
    "import numpy as np\n",
    "\n",
    "from alignment.alignment_utils import load_deep_jscc\n",
    "from alignment.alignment_model import AlignedDeepJSCC\n",
    "from alignment.alignment_training import *\n",
    "from alignment.alignment_validation import *\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4dce44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching inputs: 100%|██████████| 782/782 [00:02<00:00, 348.51it/s]\n"
     ]
    }
   ],
   "source": [
    "model1_fp = r'alignment/models/autoencoders/snr_0_seed_42.pkl'\n",
    "model2_fp = r'alignment/models/autoencoders/snr_0_seed_43.pkl'\n",
    "folder = r'psnr_vs_pilots_5'\n",
    "os.makedirs(f'alignment/models/plots/{folder}', exist_ok=True)\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "resolution = 96\n",
    "channel = 'AWGN'\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "\n",
    "train_snr = 0\n",
    "val_snr = 0\n",
    "times = 10\n",
    "c = 8\n",
    "seed = 42\n",
    "\n",
    "samples_sets = np.unique(np.logspace(0, np.log10(10000), num=100, base=10).astype(int))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder = copy.deepcopy(load_deep_jscc(model1_fp, val_snr, c, \"AWGN\").encoder)\n",
    "decoder = copy.deepcopy(load_deep_jscc(model2_fp, val_snr, c, \"AWGN\").decoder)\n",
    "\n",
    "train_loader, test_loader = get_data_loaders(dataset, resolution, batch_size, num_workers)\n",
    "data = load_alignment_dataset(model1_fp, model2_fp, train_snr, train_loader, c, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea546b",
   "metadata": {},
   "source": [
    "# No mismatch - Unaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlignedDeepJSCC(encoder, decoder, None, val_snr, \"AWGN\")\n",
    "print(f\"Unaligned {validation_vectorized(model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlignedDeepJSCC(encoder, copy.deepcopy(load_deep_jscc(model1_fp, val_snr, c, \"AWGN\").decoder), None, val_snr, \"AWGN\")\n",
    "print(f\"Aligned {validation_vectorized(model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29cfc6",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039882c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching inputs: 100%|██████████| 782/782 [00:02<00:00, 326.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1.\n",
      "Done with 2.\n",
      "Done with 3.\n",
      "Done with 4.\n",
      "Done with 5.\n",
      "Done with 6.\n",
      "Done with 7.\n",
      "Done with 8.\n",
      "Done with 9.\n",
      "Done with 10.\n",
      "Done with 11.\n",
      "Done with 12.\n",
      "Done with 13.\n",
      "Done with 14.\n",
      "Done with 16.\n",
      "Done with 17.\n",
      "Done with 19.\n",
      "Done with 21.\n",
      "Done with 23.\n",
      "Done with 25.\n",
      "Done with 28.\n",
      "Done with 31.\n",
      "Done with 34.\n",
      "Done with 37.\n",
      "Done with 41.\n",
      "Done with 45.\n",
      "Done with 49.\n",
      "Done with 54.\n",
      "Done with 59.\n",
      "Done with 65.\n",
      "Done with 72.\n",
      "Done with 79.\n",
      "Done with 86.\n",
      "Done with 95.\n",
      "Done with 104.\n",
      "Done with 114.\n",
      "Done with 126.\n",
      "Done with 138.\n",
      "Done with 151.\n",
      "Done with 166.\n",
      "Done with 183.\n",
      "Done with 200.\n",
      "Done with 220.\n",
      "Done with 242.\n",
      "Done with 265.\n",
      "Done with 291.\n",
      "Done with 319.\n",
      "Done with 351.\n",
      "Done with 385.\n",
      "Done with 422.\n",
      "Done with 464.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m permutation = torch.randperm(\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n_samples \u001b[38;5;129;01min\u001b[39;00m samples_sets:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     aligner = \u001b[43mtrain_linear_aligner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpermutation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_snr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     aligner_fp = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33malignment/models/plots/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfolder\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/aligner_linear_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.pkl\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(aligner_fp, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/Deep-JSCC-PyTorch/alignment/alignment_training.py:134\u001b[39m, in \u001b[36mtrain_linear_aligner\u001b[39m\u001b[34m(data, permutation, n_samples, train_snr, regularization)\u001b[39m\n\u001b[32m    132\u001b[39m indices = permutation[:n_samples]\n\u001b[32m    133\u001b[39m subset = Subset(data, indices)\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m matrix_1, matrix_2 = \u001b[43mdataset_to_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m aligner_least_squares(matrix_1, matrix_2, train_snr, regularization)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/Deep-JSCC-PyTorch/alignment/alignment_training.py:98\u001b[39m, in \u001b[36mdataset_to_matrices\u001b[39m\u001b[34m(dataset, batch_size)\u001b[39m\n\u001b[32m     95\u001b[39m data_1 = []\n\u001b[32m     96\u001b[39m data_2 = []\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/utils/data/dataset.py:416\u001b[39m, in \u001b[36mSubset.__getitems__\u001b[39m\u001b[34m(self, indices)\u001b[39m\n\u001b[32m    414\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__([\u001b[38;5;28mself\u001b[39m.indices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m416\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/Deep-JSCC-PyTorch/alignment/alignment_training.py:41\u001b[39m, in \u001b[36mAlignmentDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     40\u001b[39m     out1 = \u001b[38;5;28mself\u001b[39m.model1(x)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     out2 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.flat:\n\u001b[32m     43\u001b[39m     out1 = out1.flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/Deep-JSCC-PyTorch/model.py:110\u001b[39m, in \u001b[36m_Encoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    108\u001b[39m     \u001b[38;5;66;03m# x = self.imgae_normalization(x)\u001b[39;00m\n\u001b[32m    109\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv1(x)\n\u001b[32m--> \u001b[39m\u001b[32m110\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv3(x)\n\u001b[32m    112\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.conv4(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/repos/Deep-JSCC-PyTorch/model.py:49\u001b[39m, in \u001b[36m_ConvWithPReLU.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m     x = \u001b[38;5;28mself\u001b[39m.prelu(x)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:554\u001b[39m, in \u001b[36mConv2d.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    553\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.13/site-packages/torch/nn/modules/conv.py:549\u001b[39m, in \u001b[36mConv2d._conv_forward\u001b[39m\u001b[34m(self, input, weight, bias)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.padding_mode != \u001b[33m\"\u001b[39m\u001b[33mzeros\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.conv2d(\n\u001b[32m    539\u001b[39m         F.pad(\n\u001b[32m    540\u001b[39m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m._reversed_padding_repeated_twice, mode=\u001b[38;5;28mself\u001b[39m.padding_mode\n\u001b[32m   (...)\u001b[39m\u001b[32m    547\u001b[39m         \u001b[38;5;28mself\u001b[39m.groups,\n\u001b[32m    548\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgroups\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "data.flat = True\n",
    "\n",
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner = train_linear_aligner(data, permutation, n_samples, train_snr)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_linear_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner, f)\n",
    "\n",
    "    print(f\"Done with {n_samples}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1dd758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model, 1000 samples got a PSNR of 16.83\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_linear_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, channel)\n",
    "\n",
    "    print(f\"Linear model, {n_samples} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times, device):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f355d4",
   "metadata": {},
   "source": [
    "# Linear Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:10<00:00, 76.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1000. Trained for 45 epochs.\n"
     ]
    }
   ],
   "source": [
    "data.flat = False\n",
    "\n",
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "    \n",
    "    aligner, epoch = train_neural_aligner(data, permutation, n_samples, batch_size, resolution, 6, train_snr, device)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_neural_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner.to(\"cpu\"), f)\n",
    "\n",
    "    print(f\"Done with {n_samples}. Trained for {epoch} epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bce7558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural model, 1000 samples got a PSNR of 17.13\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_neural_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Neural model, {n_samples} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times, device):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a182d8b",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c4b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:08<00:00, 87.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 10000. Trained for 12 epochs.\n"
     ]
    }
   ],
   "source": [
    "data.flat = False\n",
    "\n",
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "    \n",
    "    aligner, epoch = train_mlp_aligner(data, permutation, n_samples, batch_size, resolution, 6, train_snr, device)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_mlp_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner.to(\"cpu\"), f)\n",
    "\n",
    "    print(f\"Done with {n_samples}. Trained for {epoch} epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f91d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP model, 10000 samples got a PSNR of 18.16\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_mlp_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"MLP model, {n_samples} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times, device):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6147f",
   "metadata": {},
   "source": [
    "# Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0209c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1. Trained for 168 epochs.\n",
      "Done with 2. Trained for 204 epochs.\n",
      "Done with 3. Trained for 289 epochs.\n",
      "Done with 4. Trained for 250 epochs.\n",
      "Done with 5. Trained for 237 epochs.\n",
      "Done with 6. Trained for 217 epochs.\n",
      "Done with 7. Trained for 278 epochs.\n",
      "Done with 8. Trained for 305 epochs.\n",
      "Done with 9. Trained for 280 epochs.\n",
      "Done with 10. Trained for 293 epochs.\n",
      "Done with 11. Trained for 299 epochs.\n",
      "Done with 12. Trained for 334 epochs.\n",
      "Done with 13. Trained for 315 epochs.\n",
      "Done with 14. Trained for 324 epochs.\n",
      "Done with 16. Trained for 341 epochs.\n",
      "Done with 17. Trained for 350 epochs.\n",
      "Done with 19. Trained for 342 epochs.\n",
      "Done with 21. Trained for 397 epochs.\n",
      "Done with 23. Trained for 341 epochs.\n",
      "Done with 25. Trained for 368 epochs.\n",
      "Done with 28. Trained for 309 epochs.\n",
      "Done with 31. Trained for 368 epochs.\n",
      "Done with 34. Trained for 357 epochs.\n",
      "Done with 37. Trained for 457 epochs.\n",
      "Done with 41. Trained for 414 epochs.\n",
      "Done with 45. Trained for 421 epochs.\n",
      "Done with 49. Trained for 424 epochs.\n",
      "Done with 54. Trained for 430 epochs.\n",
      "Done with 59. Trained for 448 epochs.\n",
      "Done with 65. Trained for 454 epochs.\n",
      "Done with 72. Trained for 358 epochs.\n",
      "Done with 79. Trained for 293 epochs.\n",
      "Done with 86. Trained for 308 epochs.\n",
      "Done with 95. Trained for 302 epochs.\n",
      "Done with 104. Trained for 337 epochs.\n",
      "Done with 114. Trained for 298 epochs.\n",
      "Done with 126. Trained for 313 epochs.\n",
      "Done with 138. Trained for 215 epochs.\n",
      "Done with 151. Trained for 274 epochs.\n",
      "Done with 166. Trained for 256 epochs.\n",
      "Done with 183. Trained for 268 epochs.\n",
      "Done with 200. Trained for 237 epochs.\n",
      "Done with 220. Trained for 214 epochs.\n",
      "Done with 242. Trained for 222 epochs.\n",
      "Done with 265. Trained for 208 epochs.\n",
      "Done with 291. Trained for 157 epochs.\n",
      "Done with 319. Trained for 180 epochs.\n",
      "Done with 351. Trained for 160 epochs.\n",
      "Done with 385. Trained for 141 epochs.\n",
      "Done with 422. Trained for 160 epochs.\n",
      "Done with 464. Trained for 128 epochs.\n",
      "Done with 509. Trained for 125 epochs.\n",
      "Done with 559. Trained for 105 epochs.\n",
      "Done with 613. Trained for 109 epochs.\n",
      "Done with 673. Trained for 100 epochs.\n",
      "Done with 739. Trained for 93 epochs.\n",
      "Done with 811. Trained for 101 epochs.\n",
      "Done with 890. Trained for 78 epochs.\n",
      "Done with 977. Trained for 89 epochs.\n",
      "Done with 1072. Trained for 78 epochs.\n",
      "Done with 1176. Trained for 72 epochs.\n",
      "Done with 1291. Trained for 66 epochs.\n",
      "Done with 1417. Trained for 78 epochs.\n",
      "Done with 1555. Trained for 64 epochs.\n",
      "Done with 1707. Trained for 55 epochs.\n",
      "Done with 1873. Trained for 60 epochs.\n",
      "Done with 2056. Trained for 58 epochs.\n",
      "Done with 2257. Trained for 62 epochs.\n",
      "Done with 2477. Trained for 55 epochs.\n",
      "Done with 2718. Trained for 47 epochs.\n",
      "Done with 2983. Trained for 38 epochs.\n",
      "Done with 3274. Trained for 40 epochs.\n",
      "Done with 3593. Trained for 35 epochs.\n",
      "Done with 3944. Trained for 46 epochs.\n",
      "Done with 4328. Trained for 32 epochs.\n",
      "Done with 4750. Trained for 32 epochs.\n",
      "Done with 5214. Trained for 34 epochs.\n",
      "Done with 5722. Trained for 33 epochs.\n",
      "Done with 6280. Trained for 25 epochs.\n",
      "Done with 6892. Trained for 28 epochs.\n",
      "Done with 7564. Trained for 27 epochs.\n",
      "Done with 8302. Trained for 25 epochs.\n",
      "Done with 9111. Trained for 34 epochs.\n",
      "Done with 10000. Trained for 33 epochs.\n"
     ]
    }
   ],
   "source": [
    "data.flat = False\n",
    "\n",
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner, epoch = train_conv_aligner(data, permutation, n_samples, c, batch_size, train_snr, device)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_conv_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner.to(\"cpu\"), f)\n",
    "\n",
    "    print(f\"Done with {n_samples}. Trained for {epoch} epochs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3286ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv model, 1 samples got a PSNR of 19.85\n",
      "Conv model, 2 samples got a PSNR of 23.71\n",
      "Conv model, 3 samples got a PSNR of 23.80\n",
      "Conv model, 4 samples got a PSNR of 24.41\n",
      "Conv model, 5 samples got a PSNR of 25.30\n",
      "Conv model, 6 samples got a PSNR of 25.68\n",
      "Conv model, 7 samples got a PSNR of 26.41\n",
      "Conv model, 8 samples got a PSNR of 26.97\n",
      "Conv model, 9 samples got a PSNR of 27.01\n",
      "Conv model, 10 samples got a PSNR of 27.43\n",
      "Conv model, 11 samples got a PSNR of 27.43\n",
      "Conv model, 12 samples got a PSNR of 27.43\n",
      "Conv model, 13 samples got a PSNR of 27.86\n",
      "Conv model, 14 samples got a PSNR of 28.20\n",
      "Conv model, 16 samples got a PSNR of 27.88\n",
      "Conv model, 17 samples got a PSNR of 28.30\n",
      "Conv model, 19 samples got a PSNR of 28.42\n",
      "Conv model, 21 samples got a PSNR of 28.26\n",
      "Conv model, 23 samples got a PSNR of 28.24\n",
      "Conv model, 25 samples got a PSNR of 28.13\n",
      "Conv model, 28 samples got a PSNR of 28.39\n",
      "Conv model, 31 samples got a PSNR of 28.20\n",
      "Conv model, 34 samples got a PSNR of 28.22\n",
      "Conv model, 37 samples got a PSNR of 28.57\n",
      "Conv model, 41 samples got a PSNR of 28.28\n",
      "Conv model, 45 samples got a PSNR of 28.26\n",
      "Conv model, 49 samples got a PSNR of 28.18\n",
      "Conv model, 54 samples got a PSNR of 28.22\n",
      "Conv model, 59 samples got a PSNR of 28.07\n",
      "Conv model, 65 samples got a PSNR of 28.29\n",
      "Conv model, 72 samples got a PSNR of 28.16\n",
      "Conv model, 79 samples got a PSNR of 28.03\n",
      "Conv model, 86 samples got a PSNR of 28.42\n",
      "Conv model, 95 samples got a PSNR of 28.53\n",
      "Conv model, 104 samples got a PSNR of 28.50\n",
      "Conv model, 114 samples got a PSNR of 28.89\n",
      "Conv model, 126 samples got a PSNR of 28.88\n",
      "Conv model, 138 samples got a PSNR of 29.05\n",
      "Conv model, 151 samples got a PSNR of 29.21\n",
      "Conv model, 166 samples got a PSNR of 29.07\n",
      "Conv model, 183 samples got a PSNR of 29.18\n",
      "Conv model, 200 samples got a PSNR of 29.17\n",
      "Conv model, 220 samples got a PSNR of 29.09\n",
      "Conv model, 242 samples got a PSNR of 28.95\n",
      "Conv model, 265 samples got a PSNR of 29.02\n",
      "Conv model, 291 samples got a PSNR of 29.00\n",
      "Conv model, 319 samples got a PSNR of 29.00\n",
      "Conv model, 351 samples got a PSNR of 29.00\n",
      "Conv model, 385 samples got a PSNR of 29.06\n",
      "Conv model, 422 samples got a PSNR of 28.97\n",
      "Conv model, 464 samples got a PSNR of 29.15\n",
      "Conv model, 509 samples got a PSNR of 29.15\n",
      "Conv model, 559 samples got a PSNR of 29.16\n",
      "Conv model, 613 samples got a PSNR of 29.13\n",
      "Conv model, 673 samples got a PSNR of 29.17\n",
      "Conv model, 739 samples got a PSNR of 29.16\n",
      "Conv model, 811 samples got a PSNR of 29.11\n",
      "Conv model, 890 samples got a PSNR of 29.15\n",
      "Conv model, 977 samples got a PSNR of 28.95\n",
      "Conv model, 1072 samples got a PSNR of 29.18\n",
      "Conv model, 1176 samples got a PSNR of 29.23\n",
      "Conv model, 1291 samples got a PSNR of 28.97\n",
      "Conv model, 1417 samples got a PSNR of 29.26\n",
      "Conv model, 1555 samples got a PSNR of 29.14\n",
      "Conv model, 1707 samples got a PSNR of 29.38\n",
      "Conv model, 1873 samples got a PSNR of 29.27\n",
      "Conv model, 2056 samples got a PSNR of 28.84\n",
      "Conv model, 2257 samples got a PSNR of 29.44\n",
      "Conv model, 2477 samples got a PSNR of 29.05\n",
      "Conv model, 2718 samples got a PSNR of 29.11\n",
      "Conv model, 2983 samples got a PSNR of 28.75\n",
      "Conv model, 3274 samples got a PSNR of 29.07\n",
      "Conv model, 3593 samples got a PSNR of 29.22\n",
      "Conv model, 3944 samples got a PSNR of 28.94\n",
      "Conv model, 4328 samples got a PSNR of 29.20\n",
      "Conv model, 4750 samples got a PSNR of 29.47\n",
      "Conv model, 5214 samples got a PSNR of 29.30\n",
      "Conv model, 5722 samples got a PSNR of 28.70\n",
      "Conv model, 6280 samples got a PSNR of 29.37\n",
      "Conv model, 6892 samples got a PSNR of 28.89\n",
      "Conv model, 7564 samples got a PSNR of 29.11\n",
      "Conv model, 8302 samples got a PSNR of 28.91\n",
      "Conv model, 9111 samples got a PSNR of 29.00\n",
      "Conv model, 10000 samples got a PSNR of 28.71\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "for n_samples in samples_sets:\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_conv_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Conv model, {n_samples} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a2ce7",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01102be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:08<00:00, 91.04it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 2.\n",
      "Done with 3.\n",
      "Done with 4.\n",
      "Done with 5.\n",
      "Done with 6.\n",
      "Done with 7.\n",
      "Done with 8.\n",
      "Done with 9.\n",
      "Done with 10.\n",
      "Done with 11.\n",
      "Done with 12.\n",
      "Done with 13.\n",
      "Done with 14.\n",
      "Done with 16.\n",
      "Done with 17.\n",
      "Done with 19.\n",
      "Done with 21.\n",
      "Done with 23.\n",
      "Done with 25.\n",
      "Done with 28.\n",
      "Done with 31.\n",
      "Done with 34.\n",
      "Done with 37.\n",
      "Done with 41.\n",
      "Done with 45.\n",
      "Done with 49.\n",
      "Done with 54.\n",
      "Done with 59.\n",
      "Done with 65.\n",
      "Done with 72.\n",
      "Done with 79.\n",
      "Done with 86.\n",
      "Done with 95.\n",
      "Done with 104.\n",
      "Done with 114.\n",
      "Done with 126.\n",
      "Done with 138.\n",
      "Done with 151.\n",
      "Done with 166.\n",
      "Done with 183.\n",
      "Done with 200.\n",
      "Done with 220.\n",
      "Done with 242.\n",
      "Done with 265.\n",
      "Done with 291.\n",
      "Done with 319.\n",
      "Done with 351.\n",
      "Done with 385.\n",
      "Done with 422.\n",
      "Done with 464.\n",
      "Done with 509.\n",
      "Done with 559.\n",
      "Done with 613.\n",
      "Done with 673.\n",
      "Done with 739.\n",
      "Done with 811.\n",
      "Done with 890.\n",
      "Done with 977.\n",
      "Done with 1072.\n",
      "Done with 1176.\n",
      "Done with 1291.\n",
      "Done with 1417.\n",
      "Done with 1555.\n",
      "Done with 1707.\n",
      "Done with 1873.\n",
      "Done with 2056.\n",
      "Done with 2257.\n",
      "Done with 2477.\n",
      "Done with 2718.\n",
      "Done with 2983.\n",
      "Done with 3274.\n",
      "Done with 3593.\n",
      "Done with 3944.\n",
      "Done with 4328.\n",
      "Done with 4750.\n",
      "Done with 5214.\n",
      "Done with 5722.\n",
      "Done with 6280.\n",
      "Done with 6892.\n",
      "Done with 7564.\n",
      "Done with 8302.\n",
      "Done with 9111.\n",
      "Done with 10000.\n"
     ]
    }
   ],
   "source": [
    "data.flat = True\n",
    "\n",
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for n_samples in samples_sets[1:]:\n",
    "\n",
    "    aligner = train_zeroshot_aligner(data, permutation, n_samples, train_snr, n_samples, device)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_zeroshot_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner, f)\n",
    "\n",
    "    print(f\"Done with {n_samples}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f0bef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroshot model, 2 samples got a PSNR of 9.91\n",
      "Zeroshot model, 3 samples got a PSNR of 9.86\n",
      "Zeroshot model, 4 samples got a PSNR of 9.90\n",
      "Zeroshot model, 5 samples got a PSNR of 10.84\n",
      "Zeroshot model, 6 samples got a PSNR of 10.95\n",
      "Zeroshot model, 7 samples got a PSNR of 11.08\n",
      "Zeroshot model, 8 samples got a PSNR of 11.31\n",
      "Zeroshot model, 9 samples got a PSNR of 11.21\n",
      "Zeroshot model, 10 samples got a PSNR of 11.23\n",
      "Zeroshot model, 11 samples got a PSNR of 11.27\n",
      "Zeroshot model, 12 samples got a PSNR of 11.27\n",
      "Zeroshot model, 13 samples got a PSNR of 11.27\n",
      "Zeroshot model, 14 samples got a PSNR of 11.48\n",
      "Zeroshot model, 16 samples got a PSNR of 11.70\n",
      "Zeroshot model, 17 samples got a PSNR of 11.85\n",
      "Zeroshot model, 19 samples got a PSNR of 11.89\n",
      "Zeroshot model, 21 samples got a PSNR of 12.10\n",
      "Zeroshot model, 23 samples got a PSNR of 12.26\n",
      "Zeroshot model, 25 samples got a PSNR of 12.31\n",
      "Zeroshot model, 28 samples got a PSNR of 12.36\n",
      "Zeroshot model, 31 samples got a PSNR of 12.49\n",
      "Zeroshot model, 34 samples got a PSNR of 12.87\n",
      "Zeroshot model, 37 samples got a PSNR of 12.98\n",
      "Zeroshot model, 41 samples got a PSNR of 13.28\n",
      "Zeroshot model, 45 samples got a PSNR of 13.44\n",
      "Zeroshot model, 49 samples got a PSNR of 13.54\n",
      "Zeroshot model, 54 samples got a PSNR of 13.65\n",
      "Zeroshot model, 59 samples got a PSNR of 13.72\n",
      "Zeroshot model, 65 samples got a PSNR of 13.83\n",
      "Zeroshot model, 72 samples got a PSNR of 13.89\n",
      "Zeroshot model, 79 samples got a PSNR of 14.06\n",
      "Zeroshot model, 86 samples got a PSNR of 14.07\n",
      "Zeroshot model, 95 samples got a PSNR of 14.27\n",
      "Zeroshot model, 104 samples got a PSNR of 14.35\n",
      "Zeroshot model, 114 samples got a PSNR of 14.53\n",
      "Zeroshot model, 126 samples got a PSNR of 14.74\n",
      "Zeroshot model, 138 samples got a PSNR of 14.95\n",
      "Zeroshot model, 151 samples got a PSNR of 14.62\n",
      "Zeroshot model, 166 samples got a PSNR of 15.23\n",
      "Zeroshot model, 183 samples got a PSNR of 15.43\n",
      "Zeroshot model, 200 samples got a PSNR of 15.59\n",
      "Zeroshot model, 220 samples got a PSNR of 15.79\n",
      "Zeroshot model, 242 samples got a PSNR of 16.00\n",
      "Zeroshot model, 265 samples got a PSNR of 16.16\n",
      "Zeroshot model, 291 samples got a PSNR of 16.36\n",
      "Zeroshot model, 319 samples got a PSNR of 16.06\n",
      "Zeroshot model, 351 samples got a PSNR of 16.70\n",
      "Zeroshot model, 385 samples got a PSNR of 16.93\n",
      "Zeroshot model, 422 samples got a PSNR of 17.14\n",
      "Zeroshot model, 464 samples got a PSNR of 17.35\n",
      "Zeroshot model, 509 samples got a PSNR of 17.58\n",
      "Zeroshot model, 559 samples got a PSNR of 17.81\n",
      "Zeroshot model, 613 samples got a PSNR of 18.06\n",
      "Zeroshot model, 673 samples got a PSNR of 18.05\n",
      "Zeroshot model, 739 samples got a PSNR of 18.59\n",
      "Zeroshot model, 811 samples got a PSNR of 18.90\n",
      "Zeroshot model, 890 samples got a PSNR of 19.19\n",
      "Zeroshot model, 977 samples got a PSNR of 19.42\n",
      "Zeroshot model, 1072 samples got a PSNR of 19.78\n",
      "Zeroshot model, 1176 samples got a PSNR of 20.09\n",
      "Zeroshot model, 1291 samples got a PSNR of 20.41\n",
      "Zeroshot model, 1417 samples got a PSNR of 20.79\n",
      "Zeroshot model, 1555 samples got a PSNR of 21.14\n",
      "Zeroshot model, 1707 samples got a PSNR of 21.51\n",
      "Zeroshot model, 1873 samples got a PSNR of 21.84\n",
      "Zeroshot model, 2056 samples got a PSNR of 21.98\n",
      "Zeroshot model, 2257 samples got a PSNR of 22.73\n",
      "Zeroshot model, 2477 samples got a PSNR of 23.15\n",
      "Zeroshot model, 2718 samples got a PSNR of 23.56\n",
      "Zeroshot model, 2983 samples got a PSNR of 23.98\n",
      "Zeroshot model, 3274 samples got a PSNR of 24.40\n",
      "Zeroshot model, 3593 samples got a PSNR of 24.80\n",
      "Zeroshot model, 3944 samples got a PSNR of 25.16\n",
      "Zeroshot model, 4328 samples got a PSNR of 25.53\n",
      "Zeroshot model, 4750 samples got a PSNR of 25.94\n",
      "Zeroshot model, 5214 samples got a PSNR of 26.29\n",
      "Zeroshot model, 5722 samples got a PSNR of 26.64\n",
      "Zeroshot model, 6280 samples got a PSNR of 26.93\n",
      "Zeroshot model, 6892 samples got a PSNR of 27.31\n",
      "Zeroshot model, 7564 samples got a PSNR of 27.64\n",
      "Zeroshot model, 8302 samples got a PSNR of 27.98\n",
      "Zeroshot model, 9111 samples got a PSNR of 28.33\n",
      "Zeroshot model, 10000 samples got a PSNR of 28.67\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "for n_samples in samples_sets[1:]:\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_zeroshot_{n_samples}.pkl'\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Zeroshot model, {n_samples} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times, device):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
