{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8766022e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/repos/Deep-JSCC-PyTorch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lorenzo/miniconda3/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.multiprocessing as mp\n",
    "import copy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from alignment.alignment_utils import load_deep_jscc, get_batch_psnr\n",
    "from alignment.alignment_model import _ConvolutionalAlignment, _LinearAlignment, _ZeroShotAlignment, AlignedDeepJSCC\n",
    "from utils import image_normalization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dataset import Vanilla\n",
    "from model import DeepJSCC\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "from channel import Channel\n",
    "from PIL import Image\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from functools import partial\n",
    "from alignment.linear_models_gpu import Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d4dce44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fp = r'alignment/models/autoencoders/upscaled_42.pkl'\n",
    "model2_fp = r'alignment/models/autoencoders/upscaled_43.pkl'\n",
    "\n",
    "train_snr = None\n",
    "val_snr = 7\n",
    "times = 10\n",
    "c = 8\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "resolution = 96\n",
    "folder = \"psnr_vs_pilots_4\"\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "channel = 'AWGN'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "samples = np.unique(np.logspace(0, np.log10(10000), num=100, base=10).astype(int))\n",
    "seed = 42\n",
    "\n",
    "os.makedirs(r'alignment/models/plots/'+folder, exist_ok=True)\n",
    "\n",
    "test_mode = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a704f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)                      # Python RNG\n",
    "    np.random.seed(seed)                   # NumPy RNG\n",
    "    torch.manual_seed(seed)                # PyTorch CPU RNG\n",
    "    torch.cuda.manual_seed(seed)           # PyTorch GPU RNG\n",
    "    torch.cuda.manual_seed_all(seed)       # All GPUs\n",
    "    torch.backends.cudnn.deterministic = True   # Deterministic cuDNN\n",
    "    torch.backends.cudnn.benchmark = False      # Disable benchmark to ensure reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73464447",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8aa868a",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8390d5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# GET DATA #\n",
    "############\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((resolution, resolution))])\n",
    "\n",
    "    train_dataset = datasets.CIFAR10(root='../dataset/', train=True, download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    test_dataset = datasets.CIFAR10(root='../dataset/', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "elif dataset == 'imagenet':\n",
    "    # the size of paper is 128\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((resolution, resolution))])\n",
    "\n",
    "    print(\"loading data of imagenet\")\n",
    "\n",
    "    train_dataset = datasets.ImageFolder(root='./dataset/ImageNet/train', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    test_dataset = Vanilla(root='./dataset/ImageNet/val', transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "elif dataset == 'imagenette':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((resolution, resolution))])\n",
    "\n",
    "    train_dataset = datasets.Imagenette(root='../dataset/', split=\"train\", download=True, transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    test_dataset = datasets.Imagenette(root='../dataset/', split=\"val\", download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    raise Exception('Unknown dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d701372",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentDataset(Dataset):\n",
    "    def __init__(self, dataloader, model1, model2, flat=False):\n",
    "        self.outputs = []\n",
    "\n",
    "        model1.eval()\n",
    "        model1.to(device)\n",
    "\n",
    "        model2.eval()\n",
    "        model2.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in tqdm(dataloader, desc=\"Computing model outputs\"):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                out1 = model1(inputs)\n",
    "                out2 = model2(inputs)\n",
    "\n",
    "                for o1, o2 in zip(out1, out2):\n",
    "                    if flat:\n",
    "                        o1 = o1.flatten()\n",
    "                        o2 = o2.flatten()\n",
    "\n",
    "                    self.outputs.append((o1.cpu(), o2.cpu()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx]  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80370903",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5886d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, dataloader, times):\n",
    "\n",
    "    model = model.to(device)\n",
    "    batch_psnr_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in dataloader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            psnr = torch.zeros(size=(inputs.shape[0], ), device=device)\n",
    "\n",
    "            for _ in range(times):\n",
    "                print(inputs.shape)\n",
    "\n",
    "                demo_image = model(inputs)\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "                gt = image_normalization('denormalization')(inputs)\n",
    "                psnr += get_batch_psnr(demo_image, gt)\n",
    "\n",
    "            psnr /= times\n",
    "            batch_mean_psnr = psnr.mean().item()\n",
    "            batch_psnr_list.append(batch_mean_psnr)\n",
    "\n",
    "    overall_mean_psnr = sum(batch_psnr_list) / len(batch_psnr_list)\n",
    "\n",
    "    return overall_mean_psnr\n",
    "\n",
    "def load_from_checkpoint(path, snr):\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace('module.','') # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    model = DeepJSCC(c=c, channel_type=channel, snr=snr)\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.change_channel(channel, snr)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef278f5",
   "metadata": {},
   "source": [
    "## Validation parallelized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41153f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_worker(model, inputs, gt, times, worker_id):\n",
    "    \"\"\"Worker function for parallel model inference\"\"\"\n",
    "    model.eval()\n",
    "    psnr_sum = torch.zeros(inputs.shape[0], device=inputs.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(times):\n",
    "            demo_image = model(inputs)\n",
    "            demo_image = image_normalization('denormalization')(demo_image)\n",
    "            psnr_sum += get_batch_psnr(demo_image, gt)\n",
    "    \n",
    "    return psnr_sum / times\n",
    "\n",
    "def validation_parallel_inference(model, dataloader, times, num_workers=None):\n",
    "    \"\"\"Version with parallel inference for multiple runs\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Auto-detect optimal number of workers\n",
    "    if num_workers is None:\n",
    "        num_workers = min(times, torch.cuda.device_count() if torch.cuda.is_available() else mp.cpu_count())\n",
    "    \n",
    "    total_psnr = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, *_ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            # Denormalize ground truth once\n",
    "            gt = image_normalization('denormalization')(inputs)\n",
    "            \n",
    "            if times == 1:\n",
    "                # No need for parallelization with single run\n",
    "                demo_image = model(inputs)\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "                batch_psnr = get_batch_psnr(demo_image, gt).sum().item()\n",
    "            else:\n",
    "                # Parallel inference for multiple runs\n",
    "                runs_per_worker = times // num_workers\n",
    "                remaining_runs = times % num_workers\n",
    "                \n",
    "                batch_psnr_sum = torch.zeros(batch_size, device=device)\n",
    "                \n",
    "                # Use thread pool for GPU parallelization (better for CUDA)\n",
    "                with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "                    futures = []\n",
    "                    \n",
    "                    # Submit jobs with different number of runs per worker\n",
    "                    for i in range(num_workers):\n",
    "                        worker_runs = runs_per_worker + (1 if i < remaining_runs else 0)\n",
    "                        if worker_runs > 0:\n",
    "                            future = executor.submit(\n",
    "                                validation_worker, \n",
    "                                model, inputs, gt, worker_runs, i\n",
    "                            )\n",
    "                            futures.append(future)\n",
    "                    \n",
    "                    # Collect results\n",
    "                    for future in futures:\n",
    "                        batch_psnr_sum += future.result()\n",
    "                \n",
    "                batch_psnr = batch_psnr_sum.sum().item()\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_samples += batch_size\n",
    "    \n",
    "    return total_psnr / total_samples\n",
    "\n",
    "def validation_parallel_batches(model, dataloader, times, num_workers=4):\n",
    "    \"\"\"Version with parallel batch processing\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    def process_batch(batch_data):\n",
    "        inputs, *_ = batch_data\n",
    "        inputs = inputs.to(device)\n",
    "        batch_size = inputs.shape[0]\n",
    "        \n",
    "        # Denormalize ground truth once\n",
    "        gt = image_normalization('denormalization')(inputs)\n",
    "        \n",
    "        # Accumulate PSNR across multiple runs\n",
    "        batch_psnr_sum = torch.zeros(batch_size, device=device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for _ in range(times):\n",
    "                demo_image = model(inputs)\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "                batch_psnr_sum += get_batch_psnr(demo_image, gt)\n",
    "        \n",
    "        batch_mean_psnr = (batch_psnr_sum / times).sum().item()\n",
    "        return batch_mean_psnr, batch_size\n",
    "    \n",
    "    # Process batches in parallel\n",
    "    with ThreadPoolExecutor(max_workers=num_workers) as executor:\n",
    "        results = list(executor.map(process_batch, dataloader))\n",
    "    \n",
    "    total_psnr = sum(psnr for psnr, _ in results)\n",
    "    total_samples = sum(samples for _, samples in results)\n",
    "    \n",
    "    return total_psnr / total_samples\n",
    "\n",
    "def validation_vectorized(model, dataloader, times):\n",
    "    \"\"\"Vectorized version for maximum efficiency when memory allows\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_psnr = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, *_ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            # Denormalize ground truth once\n",
    "            gt = image_normalization('denormalization')(inputs)\n",
    "            \n",
    "            if times == 1:\n",
    "                demo_image = model(inputs)\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "                batch_psnr = get_batch_psnr(demo_image, gt).sum().item()\n",
    "            else:\n",
    "                # Vectorized computation - process all runs at once\n",
    "                # Repeat inputs for all runs\n",
    "                inputs_repeated = inputs.repeat(times, 1, 1, 1)\n",
    "                \n",
    "                # Single forward pass for all runs\n",
    "                demo_images = model(inputs_repeated)\n",
    "                demo_images = image_normalization('denormalization')(demo_images)\n",
    "                \n",
    "                # Reshape to separate runs and batch dimension\n",
    "                demo_images = demo_images.view(times, batch_size, *demo_images.shape[1:])\n",
    "                gt_repeated = gt.unsqueeze(0).repeat(times, 1, 1, 1, 1)\n",
    "                \n",
    "                # Compute PSNR for all runs at once\n",
    "                psnr_all_runs = torch.stack([\n",
    "                    get_batch_psnr(demo_images[i], gt_repeated[i]) \n",
    "                    for i in range(times)\n",
    "                ])\n",
    "                \n",
    "                # Average across runs and sum across batch\n",
    "                batch_psnr = psnr_all_runs.mean(dim=0).sum().item()\n",
    "            \n",
    "            total_psnr += batch_psnr\n",
    "            total_samples += batch_size\n",
    "    \n",
    "    return total_psnr / total_samples\n",
    "\n",
    "# Main validation function with automatic method selection\n",
    "def validation_2(model, dataloader, times, method='auto', num_workers=None):\n",
    "    \"\"\"\n",
    "    Optimized validation with multiple parallelization strategies\n",
    "    \n",
    "    Args:\n",
    "        model: The model to validate\n",
    "        dataloader: Data loader for validation data\n",
    "        times: Number of inference runs per sample\n",
    "        method: 'auto', 'vectorized', 'parallel_inference', 'parallel_batches', or 'sequential'\n",
    "        num_workers: Number of parallel workers (auto-detected if None)\n",
    "    \"\"\"\n",
    "    \n",
    "    if method == 'auto':\n",
    "        # Auto-select best method based on conditions\n",
    "        if times == 1:\n",
    "            method = 'sequential'\n",
    "        elif times <= 4 and torch.cuda.is_available():\n",
    "            method = 'vectorized'  # Best for GPU with moderate times\n",
    "        elif times > 4:\n",
    "            method = 'parallel_inference'  # Best for many inference runs\n",
    "        else:\n",
    "            method = 'parallel_batches'  # Best for CPU or complex cases\n",
    "    \n",
    "    if method == 'vectorized':\n",
    "        return validation_vectorized(model, dataloader, times)\n",
    "    elif method == 'parallel_inference':\n",
    "        return validation_parallel_inference(model, dataloader, times, num_workers)\n",
    "    elif method == 'parallel_batches':\n",
    "        return validation_parallel_batches(model, dataloader, times, num_workers)\n",
    "    else:  # sequential\n",
    "        return validation_sequential(model, dataloader, times)\n",
    "\n",
    "def validation_sequential(model, dataloader, times):\n",
    "    \"\"\"Original optimized sequential version for comparison\"\"\"\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    total_psnr = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, *_ in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            batch_size = inputs.shape[0]\n",
    "            \n",
    "            gt = image_normalization('denormalization')(inputs)\n",
    "            batch_psnr_sum = torch.zeros(batch_size, device=device)\n",
    "            \n",
    "            for _ in range(times):\n",
    "                demo_image = model(inputs)\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "                batch_psnr_sum += get_batch_psnr(demo_image, gt)\n",
    "            \n",
    "            batch_mean_psnr = (batch_psnr_sum / times).sum().item()\n",
    "            total_psnr += batch_mean_psnr\n",
    "            total_samples += batch_size\n",
    "    \n",
    "    return total_psnr / total_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ea546b",
   "metadata": {},
   "source": [
    "# No mismatch - Unaligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6306f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder)\n",
    "decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "model = AlignedDeepJSCC(encoder, decoder, None, val_snr, \"AWGN\")\n",
    "print(f\"Unaligned {validation_vectorized(model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ea0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder)\n",
    "decoder = copy.deepcopy(model1.decoder)\n",
    "\n",
    "model = AlignedDeepJSCC(encoder, decoder, None, val_snr, \"AWGN\")\n",
    "\n",
    "print(f\"Aligned {validation_vectorized(model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b29cfc6",
   "metadata": {},
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a041dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrices(dataset, batch_size=128):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    \n",
    "    for batch in loader:\n",
    "        data_1.append(batch[0])\n",
    "        data_2.append(batch[1])\n",
    "\n",
    "    return torch.cat(data_1, dim=0), torch.cat(data_2, dim=0)\n",
    "\n",
    "def aligner_least_squares(matrix_1, matrix_2):\n",
    "    Y = matrix_1.T\n",
    "    Z = matrix_2.T\n",
    "\n",
    "    Q = Y @ Z.T @ torch.inverse(Z @ Z.T)\n",
    "\n",
    "    return _LinearAlignment(align_matrix=Q)\n",
    "\n",
    "def aligner_least_squares(matrix_1, matrix_2, n_samples):\n",
    "    Y = matrix_1.T  # [d, n]\n",
    "    Z = matrix_2.T  # [d, n]\n",
    "\n",
    "    ZZ_T = Z @ Z.T\n",
    "    YZ_T = Y @ Z.T\n",
    "\n",
    "    reg_matrix = (10000) * torch.eye(ZZ_T.size(0), device=ZZ_T.device, dtype=ZZ_T.dtype)\n",
    "    Q = YZ_T @ torch.linalg.inv(ZZ_T + reg_matrix)\n",
    "\n",
    "    return _LinearAlignment(align_matrix=Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5532a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_from_checkpoint(model1_fp, train_snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, train_snr).encoder\n",
    "\n",
    "data = AlignmentDataset(train_loader, model1, model2, flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039882c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for sample in samples:\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "\n",
    "    matrix_1, matrix_2 = dataset_to_matrices(subset)\n",
    "\n",
    "    aligner = aligner_least_squares(matrix_1, matrix_2, sample)\n",
    "\n",
    "    with open(r'alignment/models/plots/'+folder+'/aligner_linear_'+str(sample)+'.pkl', 'wb') as f:\n",
    "        pickle.dump(aligner, f)\n",
    "\n",
    "    print(f\"Done with {sample}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b1dd758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear model, 1 samples got a PSNR of 11.50\n",
      "Linear model, 2 samples got a PSNR of 11.09\n",
      "Linear model, 3 samples got a PSNR of 11.07\n",
      "Linear model, 4 samples got a PSNR of 11.28\n",
      "Linear model, 5 samples got a PSNR of 11.41\n",
      "Linear model, 6 samples got a PSNR of 11.30\n",
      "Linear model, 7 samples got a PSNR of 11.48\n",
      "Linear model, 8 samples got a PSNR of 11.44\n",
      "Linear model, 9 samples got a PSNR of 11.17\n",
      "Linear model, 10 samples got a PSNR of 11.23\n",
      "Linear model, 11 samples got a PSNR of 11.18\n",
      "Linear model, 12 samples got a PSNR of 11.12\n",
      "Linear model, 13 samples got a PSNR of 11.10\n",
      "Linear model, 14 samples got a PSNR of 11.12\n",
      "Linear model, 16 samples got a PSNR of 11.92\n",
      "Linear model, 17 samples got a PSNR of 11.61\n",
      "Linear model, 19 samples got a PSNR of 11.61\n",
      "Linear model, 21 samples got a PSNR of 12.00\n",
      "Linear model, 23 samples got a PSNR of 11.85\n",
      "Linear model, 25 samples got a PSNR of 11.71\n",
      "Linear model, 28 samples got a PSNR of 11.86\n",
      "Linear model, 31 samples got a PSNR of 11.67\n",
      "Linear model, 34 samples got a PSNR of 12.01\n",
      "Linear model, 37 samples got a PSNR of 12.10\n",
      "Linear model, 41 samples got a PSNR of 12.13\n",
      "Linear model, 45 samples got a PSNR of 12.16\n",
      "Linear model, 49 samples got a PSNR of 12.03\n",
      "Linear model, 54 samples got a PSNR of 12.07\n",
      "Linear model, 59 samples got a PSNR of 12.20\n",
      "Linear model, 65 samples got a PSNR of 12.38\n",
      "Linear model, 72 samples got a PSNR of 12.52\n",
      "Linear model, 79 samples got a PSNR of 12.54\n",
      "Linear model, 86 samples got a PSNR of 12.83\n",
      "Linear model, 95 samples got a PSNR of 13.08\n",
      "Linear model, 104 samples got a PSNR of 13.19\n",
      "Linear model, 114 samples got a PSNR of 13.32\n",
      "Linear model, 126 samples got a PSNR of 13.39\n",
      "Linear model, 138 samples got a PSNR of 13.60\n",
      "Linear model, 151 samples got a PSNR of 13.82\n",
      "Linear model, 166 samples got a PSNR of 13.98\n",
      "Linear model, 183 samples got a PSNR of 14.14\n",
      "Linear model, 200 samples got a PSNR of 14.29\n",
      "Linear model, 220 samples got a PSNR of 14.40\n",
      "Linear model, 242 samples got a PSNR of 14.54\n",
      "Linear model, 265 samples got a PSNR of 14.70\n",
      "Linear model, 291 samples got a PSNR of 14.89\n",
      "Linear model, 319 samples got a PSNR of 15.01\n",
      "Linear model, 351 samples got a PSNR of 15.17\n",
      "Linear model, 385 samples got a PSNR of 15.28\n",
      "Linear model, 422 samples got a PSNR of 15.43\n",
      "Linear model, 464 samples got a PSNR of 15.62\n",
      "Linear model, 509 samples got a PSNR of 15.71\n",
      "Linear model, 559 samples got a PSNR of 15.86\n",
      "Linear model, 613 samples got a PSNR of 16.03\n",
      "Linear model, 673 samples got a PSNR of 16.15\n",
      "Linear model, 739 samples got a PSNR of 16.30\n",
      "Linear model, 811 samples got a PSNR of 16.49\n",
      "Linear model, 890 samples got a PSNR of 16.68\n",
      "Linear model, 977 samples got a PSNR of 16.90\n",
      "Linear model, 1072 samples got a PSNR of 17.07\n",
      "Linear model, 1176 samples got a PSNR of 17.26\n",
      "Linear model, 1291 samples got a PSNR of 17.46\n",
      "Linear model, 1417 samples got a PSNR of 17.59\n",
      "Linear model, 1555 samples got a PSNR of 17.81\n",
      "Linear model, 1707 samples got a PSNR of 18.03\n",
      "Linear model, 1873 samples got a PSNR of 18.25\n",
      "Linear model, 2056 samples got a PSNR of 18.49\n",
      "Linear model, 2257 samples got a PSNR of 18.73\n",
      "Linear model, 2477 samples got a PSNR of 18.98\n",
      "Linear model, 2718 samples got a PSNR of 19.26\n",
      "Linear model, 2983 samples got a PSNR of 19.53\n",
      "Linear model, 3274 samples got a PSNR of 19.79\n",
      "Linear model, 3593 samples got a PSNR of 20.04\n",
      "Linear model, 3944 samples got a PSNR of 20.27\n",
      "Linear model, 4328 samples got a PSNR of 20.57\n",
      "Linear model, 4750 samples got a PSNR of 20.81\n",
      "Linear model, 5214 samples got a PSNR of 21.07\n",
      "Linear model, 5722 samples got a PSNR of 21.36\n",
      "Linear model, 6280 samples got a PSNR of 21.60\n",
      "Linear model, 6892 samples got a PSNR of 21.85\n",
      "Linear model, 7564 samples got a PSNR of 22.11\n",
      "Linear model, 8302 samples got a PSNR of 22.37\n",
      "Linear model, 9111 samples got a PSNR of 22.60\n",
      "Linear model, 10000 samples got a PSNR of 22.85\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder)\n",
    "decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_linear_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, channel)\n",
    "\n",
    "    print(f\"Linear model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266db86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    sample = 10000\n",
    "\n",
    "    set_seed(seed)\n",
    "    permutation = torch.randperm(len(data))\n",
    "\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "\n",
    "    matrix_1, matrix_2 = dataset_to_matrices(subset)\n",
    "\n",
    "    aligner = aligner_least_squares(matrix_1, matrix_2, sample)\n",
    "\n",
    "    print(f\"Done with {sample}.\")\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, channel)\n",
    "\n",
    "    print(f\"Linear model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f355d4",
   "metadata": {},
   "source": [
    "# Linear Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c10de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = load_from_checkpoint(model1_fp, train_snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, train_snr).encoder\n",
    "\n",
    "data = AlignmentDataset(train_loader, model1, model2, flat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2407065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for sample in samples:\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs_max = 10000\n",
    "    ratio = 6\n",
    "    patience = 10\n",
    "    check_interval = 1\n",
    "    min_delta = 1e-5\n",
    "    lambda_reg = 0.001\n",
    "\n",
    "    aligner = _LinearAlignment(size=resolution * resolution * 3 * 2 // ratio).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(aligner.parameters(), lr=1e-3, weight_decay=lambda_reg)\n",
    "    channel = Channel(\"AWGN\", train_snr)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    checks_without_improvement = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while True:\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "            \n",
    "            if train_snr is not None:\n",
    "                inputs = channel(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = aligner(inputs.to(device))\n",
    "\n",
    "            mse_loss = criterion(outputs, targets.to(device))\n",
    "            loss = inputs.shape[0] * mse_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch % check_interval == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            if best_loss - avg_loss > min_delta:\n",
    "                best_loss = avg_loss\n",
    "                best_model_state = copy.deepcopy(aligner.state_dict())\n",
    "                checks_without_improvement = 0\n",
    "            else:\n",
    "                checks_without_improvement += 1\n",
    "\n",
    "            if checks_without_improvement >= patience:\n",
    "                break\n",
    "\n",
    "        if epoch > epochs_max:\n",
    "            break\n",
    "\n",
    "    print(f\"Done with {sample}. Trained for {epoch} epochs.\")\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "\n",
    "    aligner_fp = f'alignment/models/plots/{folder}/aligner_neural_{sample}.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner.to(\"cpu\"), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bce7558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural model, 1 samples got a PSNR of 10.97\n",
      "Neural model, 2 samples got a PSNR of 10.91\n",
      "Neural model, 3 samples got a PSNR of 10.92\n",
      "Neural model, 4 samples got a PSNR of 10.93\n",
      "Neural model, 5 samples got a PSNR of 11.04\n",
      "Neural model, 6 samples got a PSNR of 11.10\n",
      "Neural model, 7 samples got a PSNR of 11.13\n",
      "Neural model, 8 samples got a PSNR of 11.22\n",
      "Neural model, 9 samples got a PSNR of 11.24\n",
      "Neural model, 10 samples got a PSNR of 11.26\n",
      "Neural model, 11 samples got a PSNR of 11.33\n",
      "Neural model, 12 samples got a PSNR of 11.44\n",
      "Neural model, 13 samples got a PSNR of 11.57\n",
      "Neural model, 14 samples got a PSNR of 11.64\n",
      "Neural model, 16 samples got a PSNR of 11.73\n",
      "Neural model, 17 samples got a PSNR of 11.81\n",
      "Neural model, 19 samples got a PSNR of 11.79\n",
      "Neural model, 21 samples got a PSNR of 12.04\n",
      "Neural model, 23 samples got a PSNR of 12.22\n",
      "Neural model, 25 samples got a PSNR of 12.19\n",
      "Neural model, 28 samples got a PSNR of 12.38\n",
      "Neural model, 31 samples got a PSNR of 12.44\n",
      "Neural model, 34 samples got a PSNR of 12.59\n",
      "Neural model, 37 samples got a PSNR of 12.63\n",
      "Neural model, 41 samples got a PSNR of 12.80\n",
      "Neural model, 45 samples got a PSNR of 12.87\n",
      "Neural model, 49 samples got a PSNR of 12.88\n",
      "Neural model, 54 samples got a PSNR of 13.11\n",
      "Neural model, 59 samples got a PSNR of 13.21\n",
      "Neural model, 65 samples got a PSNR of 13.20\n",
      "Neural model, 72 samples got a PSNR of 13.26\n",
      "Neural model, 79 samples got a PSNR of 13.26\n",
      "Neural model, 86 samples got a PSNR of 13.48\n",
      "Neural model, 95 samples got a PSNR of 13.46\n",
      "Neural model, 104 samples got a PSNR of 13.64\n",
      "Neural model, 114 samples got a PSNR of 13.73\n",
      "Neural model, 126 samples got a PSNR of 13.86\n",
      "Neural model, 138 samples got a PSNR of 13.79\n",
      "Neural model, 151 samples got a PSNR of 13.94\n",
      "Neural model, 166 samples got a PSNR of 14.07\n",
      "Neural model, 183 samples got a PSNR of 14.23\n",
      "Neural model, 200 samples got a PSNR of 14.21\n",
      "Neural model, 220 samples got a PSNR of 14.34\n",
      "Neural model, 242 samples got a PSNR of 14.58\n",
      "Neural model, 265 samples got a PSNR of 14.34\n",
      "Neural model, 291 samples got a PSNR of 14.53\n",
      "Neural model, 319 samples got a PSNR of 15.15\n",
      "Neural model, 351 samples got a PSNR of 15.04\n",
      "Neural model, 385 samples got a PSNR of 15.06\n",
      "Neural model, 422 samples got a PSNR of 15.39\n",
      "Neural model, 464 samples got a PSNR of 15.25\n",
      "Neural model, 509 samples got a PSNR of 15.79\n",
      "Neural model, 559 samples got a PSNR of 15.89\n",
      "Neural model, 613 samples got a PSNR of 16.09\n",
      "Neural model, 673 samples got a PSNR of 16.38\n",
      "Neural model, 739 samples got a PSNR of 16.57\n",
      "Neural model, 811 samples got a PSNR of 16.77\n",
      "Neural model, 890 samples got a PSNR of 16.99\n",
      "Neural model, 977 samples got a PSNR of 17.11\n",
      "Neural model, 1072 samples got a PSNR of 17.48\n",
      "Neural model, 1176 samples got a PSNR of 17.66\n",
      "Neural model, 1291 samples got a PSNR of 17.98\n",
      "Neural model, 1417 samples got a PSNR of 18.31\n",
      "Neural model, 1555 samples got a PSNR of 18.65\n",
      "Neural model, 1707 samples got a PSNR of 19.01\n",
      "Neural model, 1873 samples got a PSNR of 19.32\n",
      "Neural model, 2056 samples got a PSNR of 19.74\n",
      "Neural model, 2257 samples got a PSNR of 20.30\n",
      "Neural model, 2477 samples got a PSNR of 20.72\n",
      "Neural model, 2718 samples got a PSNR of 21.15\n",
      "Neural model, 2983 samples got a PSNR of 21.59\n",
      "Neural model, 3274 samples got a PSNR of 21.89\n",
      "Neural model, 3593 samples got a PSNR of 22.34\n",
      "Neural model, 3944 samples got a PSNR of 22.95\n",
      "Neural model, 4328 samples got a PSNR of 23.24\n",
      "Neural model, 4750 samples got a PSNR of 23.58\n",
      "Neural model, 5214 samples got a PSNR of 23.91\n",
      "Neural model, 5722 samples got a PSNR of 23.97\n",
      "Neural model, 6280 samples got a PSNR of 24.20\n",
      "Neural model, 6892 samples got a PSNR of 24.42\n",
      "Neural model, 7564 samples got a PSNR of 24.66\n",
      "Neural model, 8302 samples got a PSNR of 24.84\n",
      "Neural model, 9111 samples got a PSNR of 24.91\n",
      "Neural model, 10000 samples got a PSNR of 24.86\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder)\n",
    "decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_neural_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Neural model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed408f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    sample = 10000\n",
    "\n",
    "    set_seed(seed)\n",
    "    permutation = torch.randperm(len(data))\n",
    "\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs_max = 10000\n",
    "    ratio = 6\n",
    "    patience = 10\n",
    "    check_interval = 1\n",
    "    min_delta = 1e-5\n",
    "    lambda_reg = 0.001\n",
    "\n",
    "    aligner = _LinearAlignment(size=resolution * resolution * 3 * 2 // ratio).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(aligner.parameters(), lr=1e-3, weight_decay=lambda_reg)\n",
    "    channel = Channel(\"AWGN\", 30)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    best_model_state = None\n",
    "    checks_without_improvement = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while True:\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "\n",
    "            if train_snr is not None:\n",
    "                inputs = channel(inputs)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            outputs = aligner(inputs.to(device))\n",
    "\n",
    "            mse_loss = criterion(outputs, targets.to(device))\n",
    "            loss = inputs.shape[0] * mse_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch % check_interval == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            if best_loss - avg_loss > min_delta:\n",
    "                best_loss = avg_loss\n",
    "                best_model_state = copy.deepcopy(aligner.state_dict())\n",
    "                checks_without_improvement = 0\n",
    "            else:\n",
    "                checks_without_improvement += 1\n",
    "\n",
    "            if checks_without_improvement >= patience:\n",
    "                break\n",
    "\n",
    "        if epoch > epochs_max:\n",
    "            break\n",
    "\n",
    "    print(f\"Done with {sample}. Trained for {epoch} epochs.\")\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "\n",
    "    model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "    model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "    encoder = copy.deepcopy(model1.encoder)\n",
    "    decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Neural model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc6147f",
   "metadata": {},
   "source": [
    "# Convolutional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "509fa802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:09<00:00, 84.41it/s] \n"
     ]
    }
   ],
   "source": [
    "model1 = load_from_checkpoint(model1_fp, train_snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, train_snr).encoder\n",
    "\n",
    "data = AlignmentDataset(train_loader, model1, model2, flat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0209c166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 1. Trained for 168 epochs.\n",
      "Done with 2. Trained for 204 epochs.\n",
      "Done with 3. Trained for 289 epochs.\n",
      "Done with 4. Trained for 250 epochs.\n",
      "Done with 5. Trained for 237 epochs.\n",
      "Done with 6. Trained for 217 epochs.\n",
      "Done with 7. Trained for 278 epochs.\n",
      "Done with 8. Trained for 305 epochs.\n",
      "Done with 9. Trained for 280 epochs.\n",
      "Done with 10. Trained for 293 epochs.\n",
      "Done with 11. Trained for 299 epochs.\n",
      "Done with 12. Trained for 334 epochs.\n",
      "Done with 13. Trained for 315 epochs.\n",
      "Done with 14. Trained for 324 epochs.\n",
      "Done with 16. Trained for 341 epochs.\n",
      "Done with 17. Trained for 350 epochs.\n",
      "Done with 19. Trained for 342 epochs.\n",
      "Done with 21. Trained for 397 epochs.\n",
      "Done with 23. Trained for 341 epochs.\n",
      "Done with 25. Trained for 368 epochs.\n",
      "Done with 28. Trained for 309 epochs.\n",
      "Done with 31. Trained for 368 epochs.\n",
      "Done with 34. Trained for 357 epochs.\n",
      "Done with 37. Trained for 457 epochs.\n",
      "Done with 41. Trained for 414 epochs.\n",
      "Done with 45. Trained for 421 epochs.\n",
      "Done with 49. Trained for 424 epochs.\n",
      "Done with 54. Trained for 430 epochs.\n",
      "Done with 59. Trained for 448 epochs.\n",
      "Done with 65. Trained for 454 epochs.\n",
      "Done with 72. Trained for 358 epochs.\n",
      "Done with 79. Trained for 293 epochs.\n",
      "Done with 86. Trained for 308 epochs.\n",
      "Done with 95. Trained for 302 epochs.\n",
      "Done with 104. Trained for 337 epochs.\n",
      "Done with 114. Trained for 298 epochs.\n",
      "Done with 126. Trained for 313 epochs.\n",
      "Done with 138. Trained for 215 epochs.\n",
      "Done with 151. Trained for 274 epochs.\n",
      "Done with 166. Trained for 256 epochs.\n",
      "Done with 183. Trained for 268 epochs.\n",
      "Done with 200. Trained for 237 epochs.\n",
      "Done with 220. Trained for 214 epochs.\n",
      "Done with 242. Trained for 222 epochs.\n",
      "Done with 265. Trained for 208 epochs.\n",
      "Done with 291. Trained for 157 epochs.\n",
      "Done with 319. Trained for 180 epochs.\n",
      "Done with 351. Trained for 160 epochs.\n",
      "Done with 385. Trained for 141 epochs.\n",
      "Done with 422. Trained for 160 epochs.\n",
      "Done with 464. Trained for 128 epochs.\n",
      "Done with 509. Trained for 125 epochs.\n",
      "Done with 559. Trained for 105 epochs.\n",
      "Done with 613. Trained for 109 epochs.\n",
      "Done with 673. Trained for 100 epochs.\n",
      "Done with 739. Trained for 93 epochs.\n",
      "Done with 811. Trained for 101 epochs.\n",
      "Done with 890. Trained for 78 epochs.\n",
      "Done with 977. Trained for 89 epochs.\n",
      "Done with 1072. Trained for 78 epochs.\n",
      "Done with 1176. Trained for 72 epochs.\n",
      "Done with 1291. Trained for 66 epochs.\n",
      "Done with 1417. Trained for 78 epochs.\n",
      "Done with 1555. Trained for 64 epochs.\n",
      "Done with 1707. Trained for 55 epochs.\n",
      "Done with 1873. Trained for 60 epochs.\n",
      "Done with 2056. Trained for 58 epochs.\n",
      "Done with 2257. Trained for 62 epochs.\n",
      "Done with 2477. Trained for 55 epochs.\n",
      "Done with 2718. Trained for 47 epochs.\n",
      "Done with 2983. Trained for 38 epochs.\n",
      "Done with 3274. Trained for 40 epochs.\n",
      "Done with 3593. Trained for 35 epochs.\n",
      "Done with 3944. Trained for 46 epochs.\n",
      "Done with 4328. Trained for 32 epochs.\n",
      "Done with 4750. Trained for 32 epochs.\n",
      "Done with 5214. Trained for 34 epochs.\n",
      "Done with 5722. Trained for 33 epochs.\n",
      "Done with 6280. Trained for 25 epochs.\n",
      "Done with 6892. Trained for 28 epochs.\n",
      "Done with 7564. Trained for 27 epochs.\n",
      "Done with 8302. Trained for 25 epochs.\n",
      "Done with 9111. Trained for 34 epochs.\n",
      "Done with 10000. Trained for 33 epochs.\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "for sample in samples:\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs_max=10000\n",
    "    ratio=6\n",
    "    patience=10\n",
    "    check_interval=1\n",
    "    min_delta=1e-5\n",
    "    reg_val = 0.001\n",
    "\n",
    "    aligner = _ConvolutionalAlignment(in_channels=2*c, out_channels=2*c, kernel_size=5).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(aligner.parameters(), lr=1e-3, weight_decay=reg_val)\n",
    "    channel = Channel(\"AWGN\", train_snr)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    checks_without_improvement = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while True:\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "\n",
    "            if train_snr is not None:\n",
    "                inputs = channel(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = aligner(inputs.to(device))\n",
    "            loss = criterion(outputs, targets.to(device))\n",
    "            loss = loss * inputs.shape[0] # scale by batch size\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch % check_interval == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            if best_loss - avg_loss > min_delta:\n",
    "                best_loss = avg_loss\n",
    "                best_model_state = copy.deepcopy(aligner.state_dict())\n",
    "                checks_without_improvement = 0\n",
    "            else:\n",
    "                checks_without_improvement += 1\n",
    "\n",
    "            if checks_without_improvement >= patience:\n",
    "                break\n",
    "\n",
    "        if epoch > epochs_max:\n",
    "            break\n",
    "\n",
    "    print(f\"Done with {sample}. Trained for {epoch} epochs.\")\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_conv_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(aligner.to(\"cpu\"), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee3286ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv model, 1 samples got a PSNR of 19.85\n",
      "Conv model, 2 samples got a PSNR of 23.71\n",
      "Conv model, 3 samples got a PSNR of 23.80\n",
      "Conv model, 4 samples got a PSNR of 24.41\n",
      "Conv model, 5 samples got a PSNR of 25.30\n",
      "Conv model, 6 samples got a PSNR of 25.68\n",
      "Conv model, 7 samples got a PSNR of 26.41\n",
      "Conv model, 8 samples got a PSNR of 26.97\n",
      "Conv model, 9 samples got a PSNR of 27.01\n",
      "Conv model, 10 samples got a PSNR of 27.43\n",
      "Conv model, 11 samples got a PSNR of 27.43\n",
      "Conv model, 12 samples got a PSNR of 27.43\n",
      "Conv model, 13 samples got a PSNR of 27.86\n",
      "Conv model, 14 samples got a PSNR of 28.20\n",
      "Conv model, 16 samples got a PSNR of 27.88\n",
      "Conv model, 17 samples got a PSNR of 28.30\n",
      "Conv model, 19 samples got a PSNR of 28.42\n",
      "Conv model, 21 samples got a PSNR of 28.26\n",
      "Conv model, 23 samples got a PSNR of 28.24\n",
      "Conv model, 25 samples got a PSNR of 28.13\n",
      "Conv model, 28 samples got a PSNR of 28.39\n",
      "Conv model, 31 samples got a PSNR of 28.20\n",
      "Conv model, 34 samples got a PSNR of 28.22\n",
      "Conv model, 37 samples got a PSNR of 28.57\n",
      "Conv model, 41 samples got a PSNR of 28.28\n",
      "Conv model, 45 samples got a PSNR of 28.26\n",
      "Conv model, 49 samples got a PSNR of 28.18\n",
      "Conv model, 54 samples got a PSNR of 28.22\n",
      "Conv model, 59 samples got a PSNR of 28.07\n",
      "Conv model, 65 samples got a PSNR of 28.29\n",
      "Conv model, 72 samples got a PSNR of 28.16\n",
      "Conv model, 79 samples got a PSNR of 28.03\n",
      "Conv model, 86 samples got a PSNR of 28.42\n",
      "Conv model, 95 samples got a PSNR of 28.53\n",
      "Conv model, 104 samples got a PSNR of 28.50\n",
      "Conv model, 114 samples got a PSNR of 28.89\n",
      "Conv model, 126 samples got a PSNR of 28.88\n",
      "Conv model, 138 samples got a PSNR of 29.05\n",
      "Conv model, 151 samples got a PSNR of 29.21\n",
      "Conv model, 166 samples got a PSNR of 29.07\n",
      "Conv model, 183 samples got a PSNR of 29.18\n",
      "Conv model, 200 samples got a PSNR of 29.17\n",
      "Conv model, 220 samples got a PSNR of 29.09\n",
      "Conv model, 242 samples got a PSNR of 28.95\n",
      "Conv model, 265 samples got a PSNR of 29.02\n",
      "Conv model, 291 samples got a PSNR of 29.00\n",
      "Conv model, 319 samples got a PSNR of 29.00\n",
      "Conv model, 351 samples got a PSNR of 29.00\n",
      "Conv model, 385 samples got a PSNR of 29.06\n",
      "Conv model, 422 samples got a PSNR of 28.97\n",
      "Conv model, 464 samples got a PSNR of 29.15\n",
      "Conv model, 509 samples got a PSNR of 29.15\n",
      "Conv model, 559 samples got a PSNR of 29.16\n",
      "Conv model, 613 samples got a PSNR of 29.13\n",
      "Conv model, 673 samples got a PSNR of 29.17\n",
      "Conv model, 739 samples got a PSNR of 29.16\n",
      "Conv model, 811 samples got a PSNR of 29.11\n",
      "Conv model, 890 samples got a PSNR of 29.15\n",
      "Conv model, 977 samples got a PSNR of 28.95\n",
      "Conv model, 1072 samples got a PSNR of 29.18\n",
      "Conv model, 1176 samples got a PSNR of 29.23\n",
      "Conv model, 1291 samples got a PSNR of 28.97\n",
      "Conv model, 1417 samples got a PSNR of 29.26\n",
      "Conv model, 1555 samples got a PSNR of 29.14\n",
      "Conv model, 1707 samples got a PSNR of 29.38\n",
      "Conv model, 1873 samples got a PSNR of 29.27\n",
      "Conv model, 2056 samples got a PSNR of 28.84\n",
      "Conv model, 2257 samples got a PSNR of 29.44\n",
      "Conv model, 2477 samples got a PSNR of 29.05\n",
      "Conv model, 2718 samples got a PSNR of 29.11\n",
      "Conv model, 2983 samples got a PSNR of 28.75\n",
      "Conv model, 3274 samples got a PSNR of 29.07\n",
      "Conv model, 3593 samples got a PSNR of 29.22\n",
      "Conv model, 3944 samples got a PSNR of 28.94\n",
      "Conv model, 4328 samples got a PSNR of 29.20\n",
      "Conv model, 4750 samples got a PSNR of 29.47\n",
      "Conv model, 5214 samples got a PSNR of 29.30\n",
      "Conv model, 5722 samples got a PSNR of 28.70\n",
      "Conv model, 6280 samples got a PSNR of 29.37\n",
      "Conv model, 6892 samples got a PSNR of 28.89\n",
      "Conv model, 7564 samples got a PSNR of 29.11\n",
      "Conv model, 8302 samples got a PSNR of 28.91\n",
      "Conv model, 9111 samples got a PSNR of 29.00\n",
      "Conv model, 10000 samples got a PSNR of 28.71\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder)\n",
    "decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "for sample in samples:\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_conv_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Conv model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f42cb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_mode:\n",
    "    \n",
    "    sample = 10000\n",
    "\n",
    "    set_seed(seed)\n",
    "    permutation = torch.randperm(len(data))\n",
    "\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "    dataloader = DataLoader(subset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    epochs_max=10000\n",
    "    ratio=6\n",
    "    patience=10\n",
    "    check_interval=1\n",
    "    min_delta=1e-5\n",
    "    reg_val = 0.001\n",
    "\n",
    "    aligner = _ConvolutionalAlignment(in_channels=2*c, out_channels=2*c, kernel_size=5).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(aligner.parameters(), lr=1e-3, weight_decay=reg_val)\n",
    "    channel = Channel(\"AWGN\", train_snr)\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    checks_without_improvement = 0\n",
    "    epoch = 0\n",
    "\n",
    "    while True:\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for inputs, targets in dataloader:\n",
    "\n",
    "            if train_snr is not None:\n",
    "                inputs = channel(inputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = aligner(inputs.to(device))\n",
    "            loss = criterion(outputs, targets.to(device))\n",
    "            loss = loss * inputs.shape[0] # scale by batch size\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        epoch += 1\n",
    "\n",
    "        if epoch % check_interval == 0:\n",
    "            avg_loss = epoch_loss / len(dataloader)\n",
    "            if best_loss - avg_loss > min_delta:\n",
    "                best_loss = avg_loss\n",
    "                best_model_state = copy.deepcopy(aligner.state_dict())\n",
    "                checks_without_improvement = 0\n",
    "            else:\n",
    "                checks_without_improvement += 1\n",
    "\n",
    "            if checks_without_improvement >= patience:\n",
    "                break\n",
    "\n",
    "        if epoch > epochs_max:\n",
    "            break\n",
    "\n",
    "    print(f\"Done with {sample}. Trained for {epoch} epochs.\")\n",
    "\n",
    "    # Restore best model\n",
    "    if best_model_state is not None:\n",
    "        aligner.load_state_dict(best_model_state)\n",
    "\n",
    "    model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "    model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "    encoder = copy.deepcopy(model1.encoder)\n",
    "    decoder = copy.deepcopy(model2.decoder)\n",
    "\n",
    "    aligned_model = AlignedDeepJSCC(encoder, decoder, aligner, val_snr, \"AWGN\")\n",
    "\n",
    "    print(f\"Conv model, {sample} samples got a PSNR of {validation_vectorized(aligned_model, test_loader, times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320a2ce7",
   "metadata": {},
   "source": [
    "# Zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db6eaf34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:12<00:00, 64.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model1 = load_from_checkpoint(model1_fp, train_snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, train_snr).encoder\n",
    "\n",
    "data = AlignmentDataset(train_loader, model1, model2, flat=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0284b542",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "permutation = torch.randperm(len(data))\n",
    "\n",
    "samples_zeroshot = set()\n",
    "for num in samples:\n",
    "    if num % 2 != 0:\n",
    "        num += 1\n",
    "    samples_zeroshot.add(num)\n",
    "samples_zeroshot = sorted(samples_zeroshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01102be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in samples_zeroshot[1:]:\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "\n",
    "    dataloader = DataLoader(subset, batch_size=len(subset))\n",
    "    input, output = next(iter(dataloader))\n",
    "\n",
    "    flattened_image_size = resolution * resolution\n",
    "\n",
    "    try:\n",
    "\n",
    "        baseline = Baseline(\n",
    "            input_dim=flattened_image_size,\n",
    "            output_dim=flattened_image_size,\n",
    "            channel_matrix=torch.eye(1, dtype=torch.complex64),\n",
    "            snr=train_snr,\n",
    "            channel_usage=None,\n",
    "            typology='pre',\n",
    "            strategy='PFE',\n",
    "            use_channel=True if train_snr is not None else False,\n",
    "            seed=seed,\n",
    "        )\n",
    "\n",
    "        baseline.fit(input, output)\n",
    "\n",
    "    except RuntimeError:\n",
    "        \n",
    "        print(f\"Skipped {sample}.\")\n",
    "        continue\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_zeroshot_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'wb') as f:\n",
    "        pickle.dump(baseline, f)\n",
    "\n",
    "    print(f\"Done with {sample}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1db0ec0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zeroshot model, 10000 samples got a PSNR of 24.807317502939018\n"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "encoder = copy.deepcopy(model1.encoder).to(device)\n",
    "decoder = copy.deepcopy(model2.decoder).to(device)\n",
    "\n",
    "for sample in samples_zeroshot[-1:]:\n",
    "\n",
    "    aligner_fp = r'alignment/models/plots/'+folder+'/aligner_zeroshot_'+str(sample)+'.pkl'\n",
    "\n",
    "    with open(aligner_fp, 'rb') as f:\n",
    "        aligner = pickle.load(f)\n",
    "\n",
    "    if val_snr is not None:\n",
    "        aligner.use_channel = True\n",
    "        aligner.snr = val_snr\n",
    "    \n",
    "    else:\n",
    "        aligner.use_channel = False\n",
    "        aligner.snr = val_snr\n",
    "\n",
    "    batch_psnr_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for inputs, _ in test_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.squeeze()\n",
    "            psnr_all = 0.0\n",
    "\n",
    "            for _ in range(times):\n",
    "\n",
    "                demo_image = encoder(inputs)\n",
    "                shape = demo_image.shape\n",
    "\n",
    "                demo_image = demo_image.reshape(shape[0], -1)\n",
    "                demo_image = aligner.transform(demo_image)\n",
    "\n",
    "                demo_image = demo_image.reshape(shape)\n",
    "                demo_image = decoder(demo_image)\n",
    "\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "\n",
    "                gt = image_normalization('denormalization')(inputs)\n",
    "                psnr_all += get_batch_psnr(demo_image, gt)\n",
    "\n",
    "            psnr_all /= times\n",
    "            batch_mean_psnr = psnr_all.mean().item()\n",
    "            batch_psnr_list.append(batch_mean_psnr)\n",
    "\n",
    "    overall_mean_psnr = sum(batch_psnr_list) / len(batch_psnr_list)\n",
    "\n",
    "    print(f\"Zeroshot model, {sample} samples got a PSNR of {overall_mean_psnr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a7673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 10000.\n",
      "Zeroshot model, 10000 samples got a PSNR of 23.538920226370454\n"
     ]
    }
   ],
   "source": [
    "if test_mode:\n",
    "    set_seed(seed)\n",
    "    permutation = torch.randperm(len(data))\n",
    "\n",
    "    sample = 10000\n",
    "\n",
    "    indices = permutation[:sample]\n",
    "    subset = Subset(data, indices)\n",
    "\n",
    "    dataloader = DataLoader(subset, batch_size=len(subset))\n",
    "    input, output = next(iter(dataloader))\n",
    "\n",
    "    flattened_image_size = resolution * resolution\n",
    "\n",
    "    baseline = Baseline(\n",
    "        input_dim=flattened_image_size,\n",
    "        output_dim=flattened_image_size,\n",
    "        channel_matrix=torch.eye(1, dtype=torch.complex64),\n",
    "        snr=train_snr,\n",
    "        channel_usage=None,\n",
    "        typology='pre',\n",
    "        strategy='PFE',\n",
    "        use_channel=True if train_snr is not None else False,\n",
    "        seed=seed,\n",
    "    )\n",
    "\n",
    "    baseline.fit(input, output)\n",
    "\n",
    "    print(f\"Done with {sample}.\")\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "    model1 = load_deep_jscc(model1_fp, val_snr, c, \"AWGN\")\n",
    "    model2 = load_deep_jscc(model2_fp, val_snr, c, \"AWGN\")\n",
    "\n",
    "    encoder = copy.deepcopy(model1.encoder).to(device)\n",
    "    decoder = copy.deepcopy(model2.decoder).to(device)\n",
    "    aligner = baseline\n",
    "\n",
    "    batch_psnr_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for inputs, _ in test_loader:\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            inputs = inputs.squeeze()\n",
    "            psnr_all = 0.0\n",
    "\n",
    "            for _ in range(times):\n",
    "\n",
    "                demo_image = encoder(inputs)\n",
    "                shape = demo_image.shape\n",
    "\n",
    "                demo_image = demo_image.reshape(shape[0], -1)\n",
    "                demo_image = aligner.transform(demo_image)\n",
    "\n",
    "                demo_image = demo_image.reshape(shape)\n",
    "                demo_image = decoder(demo_image)\n",
    "\n",
    "                demo_image = image_normalization('denormalization')(demo_image)\n",
    "\n",
    "                gt = image_normalization('denormalization')(inputs)\n",
    "                psnr_all += get_batch_psnr(demo_image, gt)\n",
    "\n",
    "            psnr_all /= times\n",
    "            batch_mean_psnr = psnr_all.mean().item()\n",
    "            batch_psnr_list.append(batch_mean_psnr)\n",
    "\n",
    "    overall_mean_psnr = sum(batch_psnr_list) / len(batch_psnr_list)\n",
    "\n",
    "    print(f\"Zeroshot model, {sample} samples got a PSNR of {overall_mean_psnr}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
