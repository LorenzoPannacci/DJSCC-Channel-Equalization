{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dd6854",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25b9b5b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\File\\Repos\\Deep-JSCC-PyTorch\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "from dataset import Vanilla\n",
    "from model import DeepJSCC\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8954683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fp = r'alignment\\models\\seed42_v1.pkl'\n",
    "model2_fp = r'alignment\\models\\seed43_v1.pkl'\n",
    "saved = r'out\\checkpoints\\CIFAR10_8_7.0_0.17_AWGN_11h35m08s_on_Mar_27_2025\\epoch_999.pkl'\n",
    "snr = 7\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "channel = 'AWGN'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "444df1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "############\n",
    "# GET DATA #\n",
    "############\n",
    "\n",
    "if dataset == 'cifar10':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "    train_dataset = datasets.CIFAR10(root='../dataset/', train=True, download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = datasets.CIFAR10(root='../dataset/', train=False, download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "elif dataset == 'imagenet':\n",
    "    # the size of paper is 128\n",
    "    transform = transforms.Compose( [transforms.ToTensor(), transforms.Resize((128, 128))])\n",
    "\n",
    "    print(\"loading data of imagenet\")\n",
    "    train_dataset = datasets.ImageFolder(root='./dataset/ImageNet/train', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = Vanilla(root='./dataset/ImageNet/val', transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "else:\n",
    "    raise Exception('Unknown dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e3e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_checkpoint(path, snr):\n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace('module.','') # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    file_name = os.path.basename(os.path.dirname(saved))\n",
    "    c = file_name.split('_')[1]\n",
    "    c = int(c)\n",
    "    model = DeepJSCC(c=c, channel_type=channel, snr=snr)\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.change_channel(channel, snr)\n",
    "\n",
    "    return model\n",
    "\n",
    "model1 = load_from_checkpoint(model1_fp, snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, snr).encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7268960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlignmentDataset(Dataset):\n",
    "    def __init__(self, dataloader, model1, model2, device='cpu'):\n",
    "        self.outputs = []\n",
    "\n",
    "        model1.eval()\n",
    "        model1.to(device)\n",
    "\n",
    "        model2.eval()\n",
    "        model2.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in tqdm(dataloader, desc=\"Computing model outputs\"):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                out1 = model1(inputs)\n",
    "                out2 = model2(inputs)\n",
    "\n",
    "                for o1, o2 in zip(out1, out2):\n",
    "                    o1 = o1.flatten()\n",
    "                    o2 = o2.flatten()\n",
    "                    self.outputs.append((o1.cpu(), o2.cpu()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d561750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:34<00:00, 22.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# 50.000 (samples) / 64 (batch size) = 781.25 -> 782 (batches to compute) \n",
    "data = AlignmentDataset(train_loader, model1, model2, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1c2d6",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c57e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrices(dataset, batch_size=128):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    for batch in loader:\n",
    "        data_1.append(batch[0])\n",
    "        data_2.append(batch[1])\n",
    "    return torch.cat(data_1, dim=0), torch.cat(data_2, dim=0)\n",
    "\n",
    "matrix_1, matrix_2 = dataset_to_matrices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2f5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "# LEAST SQUARES #\n",
    "#################\n",
    "\n",
    "Y = matrix_1.T\n",
    "Z = matrix_2.T\n",
    "\n",
    "Q = Y @ Z.T @ torch.inverse(Z @ Z.T)\n",
    "\n",
    "with open(r'alignment\\models\\aligner.pkl', 'wb') as f:\n",
    "    pickle.dump(Q, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9802bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "# LINEAR MODEL SGD TRAINING #\n",
    "#############################\n",
    "\n",
    "X = matrix_1\n",
    "Y = matrix_2\n",
    "\n",
    "# define linear model\n",
    "model = nn.Linear(1024, 1024, bias=True)\n",
    "\n",
    "# define loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# training loop\n",
    "num_epochs = 1000\n",
    "for epoch, _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "# get the weight and bias\n",
    "weights = model.weight.data   # shape: [1024, 1024]\n",
    "bias = model.bias.data        # shape: [1024]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
