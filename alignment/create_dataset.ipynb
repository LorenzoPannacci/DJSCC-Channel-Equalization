{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dd6854",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8954683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = r\"alignment\\models\\seed42_v1.pkl\"\n",
    "model2 = r\"alignment\\models\\seed43_v1.pkl\"\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "channel = 'AWGN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5f77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Github repos\\Deep-JSCC-PyTorch\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe07b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset import Vanilla\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from channel import Channel\n",
    "from model import DeepJSCC, _Encoder, _Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444df1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load data\n",
    "if dataset == 'cifar10':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "    train_dataset = datasets.CIFAR10(root='../dataset/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = datasets.CIFAR10(root='../dataset/', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "elif dataset == 'imagenet':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Resize((128, 128))])  # the size of paper is 128\n",
    "    print(\"loading data of imagenet\")\n",
    "    train_dataset = datasets.ImageFolder(root='./dataset/ImageNet/train', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = Vanilla(root='./dataset/ImageNet/val', transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "else:\n",
    "    raise Exception('Unknown dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e98a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fp = r'alignment\\models\\seed42_v1.pkl'\n",
    "model2_fp = r'alignment\\models\\seed43_v1.pkl'\n",
    "saved = r'out\\checkpoints\\CIFAR10_8_7.0_0.17_AWGN_11h35m08s_on_Mar_27_2025\\epoch_999.pkl'\n",
    "snr = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e3e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_checkpoint(path, snr):\n",
    "    state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace('module.','') # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    file_name = os.path.basename(os.path.dirname(saved))\n",
    "    c = file_name.split('_')[1]\n",
    "    c = int(c)\n",
    "    model = DeepJSCC(c=c, channel_type=channel, snr=snr)\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.change_channel(channel, snr)\n",
    "\n",
    "    return model\n",
    "\n",
    "model1 = load_from_checkpoint(model1_fp, snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, snr).encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7268960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputDataset(Dataset):\n",
    "    def __init__(self, dataloader, model1, model2, device='cpu'):\n",
    "        self.outputs = []\n",
    "\n",
    "        # Ensure models are in eval mode\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "\n",
    "        # Move models to the correct device\n",
    "        model1.to(device)\n",
    "        model2.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in tqdm(dataloader, desc=\"Computing model outputs\"):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                out1 = model1(inputs)\n",
    "                out2 = model2(inputs)\n",
    "\n",
    "                for o1, o2 in zip(out1, out2):\n",
    "                    o1 = o1.flatten()\n",
    "                    o2 = o2.flatten()\n",
    "                    self.outputs.append((o1.cpu(), o2.cpu()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d561750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [01:38<00:00,  7.97it/s] \n"
     ]
    }
   ],
   "source": [
    "# 50.000 (samples) / 64 (batch size) = 781.25 -> 782 (batches to compute) \n",
    "\n",
    "data = ModelOutputDataset(train_loader, model1, model2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77060da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820cdfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to pickle?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1c2d6",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c57e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrices(dataset, batch_size=128):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    for batch in loader:\n",
    "        data_1.append(batch[0])\n",
    "        data_2.append(batch[1])\n",
    "    return torch.cat(data_1, dim=0), torch.cat(data_2, dim=0)\n",
    "\n",
    "# Usage\n",
    "matrix_1, matrix_2 = dataset_to_matrices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef2f5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = matrix_1.T\n",
    "Z = matrix_2.T\n",
    "\n",
    "Q = Y @ Z.T @ torch.inverse(Z @ Z.T)\n",
    "\n",
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6fbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from channel import Channel\n",
    "from model import DeepJSCC, _Encoder, _Decoder\n",
    "\n",
    "class AlignedDeepJSCC(nn.Module):\n",
    "    def __init__(self, model1, model2, aligner):\n",
    "        super(AlignedDeepJSCC, self).__init__()\n",
    "\n",
    "        # get encoder from model1\n",
    "        self.encoder = model1.encoder\n",
    "        self.snr = model1.snr\n",
    "\n",
    "        if self.snr is not None:\n",
    "            self.channel = model1.channel\n",
    "\n",
    "        # get aligner\n",
    "        self.aligner = aligner\n",
    "\n",
    "        # get decoder from model2\n",
    "        self.decoder = model2.decoder\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        if hasattr(self, 'channel') and self.channel is not None:\n",
    "            z = self.channel(z)\n",
    "\n",
    "        z = self.aligner(z)\n",
    "        \n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def change_channel(self, channel_type='AWGN', snr=None):\n",
    "        if snr is None:\n",
    "            self.channel = None\n",
    "        else:\n",
    "            self.channel = Channel(channel_type, snr)\n",
    "\n",
    "    def get_channel(self):\n",
    "        if hasattr(self, 'channel') and self.channel is not None:\n",
    "            return self.channel.get_channel()\n",
    "        return None\n",
    "\n",
    "    def loss(self, prd, gt):\n",
    "        criterion = nn.MSELoss(reduction='mean')\n",
    "        loss = criterion(prd, gt)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9802bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "X = matrix_1\n",
    "Y = matrix_2\n",
    "\n",
    "# Define the linear model\n",
    "model = nn.Linear(1024, 1024, bias=True)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 1000\n",
    "for epoch, _ in tqdm(range(num_epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X)\n",
    "    loss = criterion(outputs, Y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item():.6f}')\n",
    "\n",
    "# Get the weight and bias\n",
    "weights = model.weight.data   # Shape: [1024, 1024]\n",
    "bias = model.bias.data        # Shape: [1024]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
