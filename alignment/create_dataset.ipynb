{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53dd6854",
   "metadata": {},
   "source": [
    "# Create data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8954683",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = r\"alignment\\models\\seed42_v1.pkl\"\n",
    "model2 = r\"alignment\\models\\seed43_v1.pkl\"\n",
    "\n",
    "dataset = \"cifar10\"\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "channel = 'AWGN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f5f77f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\File\\Repos\\Deep-JSCC-PyTorch\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe07b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from dataset import Vanilla\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "from channel import Channel\n",
    "from model import DeepJSCC, _Encoder, _Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "444df1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# load data\n",
    "if dataset == 'cifar10':\n",
    "    transform = transforms.Compose([transforms.ToTensor(), ])\n",
    "    train_dataset = datasets.CIFAR10(root='../dataset/', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = datasets.CIFAR10(root='../dataset/', train=False,\n",
    "                                    download=True, transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "elif dataset == 'imagenet':\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Resize((128, 128))])  # the size of paper is 128\n",
    "    print(\"loading data of imagenet\")\n",
    "    train_dataset = datasets.ImageFolder(root='./dataset/ImageNet/train', transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "    test_dataset = Vanilla(root='./dataset/ImageNet/val', transform=transform)\n",
    "    test_loader = DataLoader(test_dataset, shuffle=True,\n",
    "                                batch_size=batch_size, num_workers=num_workers)\n",
    "else:\n",
    "    raise Exception('Unknown dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65e98a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_fp = r'alignment\\models\\seed42_v1.pkl'\n",
    "model2_fp = r'alignment\\models\\seed43_v1.pkl'\n",
    "saved = r'out\\checkpoints\\CIFAR10_8_7.0_0.17_AWGN_11h35m08s_on_Mar_27_2025\\epoch_999.pkl'\n",
    "snr = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80e3e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_checkpoint(path, snr):\n",
    "    state_dict = torch.load(path, map_location=torch.device('cpu'))\n",
    "    from collections import OrderedDict\n",
    "    new_state_dict = OrderedDict()\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace('module.','') # remove `module.`\n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    file_name = os.path.basename(os.path.dirname(saved))\n",
    "    c = file_name.split('_')[1]\n",
    "    c = int(c)\n",
    "    model = DeepJSCC(c=c, channel_type=channel, snr=snr)\n",
    "\n",
    "    model.load_state_dict(new_state_dict)\n",
    "    model.change_channel(channel, snr)\n",
    "\n",
    "    return model\n",
    "\n",
    "model1 = load_from_checkpoint(model1_fp, snr).encoder\n",
    "model2 = load_from_checkpoint(model2_fp, snr).encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7268960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputDataset(Dataset):\n",
    "    def __init__(self, dataloader, model1, model2, device='cpu'):\n",
    "        self.outputs = []\n",
    "\n",
    "        # Ensure models are in eval mode\n",
    "        model1.eval()\n",
    "        model2.eval()\n",
    "\n",
    "        # Move models to the correct device\n",
    "        model1.to(device)\n",
    "        model2.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, _ in tqdm(dataloader, desc=\"Computing model outputs\"):\n",
    "                inputs = inputs.to(device)\n",
    "\n",
    "                out1 = model1(inputs)\n",
    "                out2 = model2(inputs)\n",
    "\n",
    "                for o1, o2 in zip(out1, out2):\n",
    "                    o1 = o1.flatten()\n",
    "                    o2 = o2.flatten()\n",
    "                    self.outputs.append((o1.cpu(), o2.cpu()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.outputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.outputs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d561750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing model outputs: 100%|██████████| 782/782 [00:28<00:00, 27.17it/s] \n"
     ]
    }
   ],
   "source": [
    "data = ModelOutputDataset(train_loader, model1, model2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77060da4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1024])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why this shape?\n",
    "\n",
    "data.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b1c2d6",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c57e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_matrices(dataset, batch_size=128):\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    for batch in loader:\n",
    "        data_1.append(batch[0])\n",
    "        data_2.append(batch[1])\n",
    "    return torch.cat(data_1, dim=0), torch.cat(data_2, dim=0)\n",
    "\n",
    "# Usage\n",
    "matrix_1, matrix_2 = dataset_to_matrices(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2f5aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = matrix_1\n",
    "Z = matrix_2\n",
    "\n",
    "Q = Y @ Z.T @ torch.inverse(Z @ Z.T)\n",
    "\n",
    "Q.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
